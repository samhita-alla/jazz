{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import music21\n",
    "# to search for filenames with wildcard characters\n",
    "from glob import glob\n",
    "import IPython\n",
    "# tqdm is used to predict the remaining time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tensorflow.python.keras import utils\n",
    "import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = glob('datasets/*.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "    for file in songs:\n",
    "        # convert .mid file to a stream object\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = []\n",
    "        try:\n",
    "            # partition a stream into parts for each unique instrument\n",
    "            parts = instrument.partitionByInstrument(midi)\n",
    "            print(typeof(parts))\n",
    "        except:\n",
    "            pass\n",
    "        # if there're instrument parts\n",
    "        if parts:\n",
    "            # To use recursion for a stream to check if there're inner substreams available\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            # A very important read-only property that returns a new Stream that has all \n",
    "            # sub-containers “flattened” within it, that is, it returns a new Stream where \n",
    "            # no elements nest within other elements.\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            # extract pitch if the element is a note\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            # append the normal form of chord(integers) to the notes list\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    with open('notes','wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notes which we'll be getting from the previous function are strings. A NN accepts inputs\n",
    "# which are real values, hence we need to map these strings into real values\n",
    "def prep_seq(notes, n_vocab):\n",
    "    seq_length = 100\n",
    "    # Remove duplicates from the notes list\n",
    "    pitchnames = sorted(set(i for i in notes))\n",
    "    # A dict to map these values and intgers\n",
    "    notes_to_int = dict((note,n) for n, note in enumerate(pitchnames))\n",
    "    net_in = []\n",
    "    net_out = []\n",
    "    # iterate over the whole notes list by selecting 100 notes every time, and the 101st will be \n",
    "    # the sequence output\n",
    "    for i in range(0, len(notes)-seq_length,1):\n",
    "        seq_in = notes[i:i+seq_length]\n",
    "        seq_out = notes[i+seq_length]\n",
    "        net_in.append([notes_to_int[j] for j in seq_in])\n",
    "        net_out.append(notes_to_int[seq_out])\n",
    "    number_of_patterns = len(net_in)\n",
    "    \n",
    "    # reshaping the input into LSTM compatible - samples, timesteps, features\n",
    "    # Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "    # Time Steps. One time step is one point of observation in the sample.\n",
    "    # Features. One feature is one observation at a time step.\n",
    "    net_in = np.reshape(net_in, (number_of_patterns, seq_length, 1))\n",
    "    \n",
    "    # Input normalization\n",
    "    net_in = net_in/float(n_vocab)\n",
    "    \n",
    "    net_out = utils.to_categorical(net_out)\n",
    "    return (net_in, net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, LSTM, Dense, Dropout, Flatten\n",
    "def net_arch(net_in, n_vocab):\n",
    "    model = Sequential()\n",
    "    # 128 - dimensionality of the output space.\n",
    "    # let’s say we have an input with shape (num_seq, seq_len, num_feature). If we \n",
    "    # don’t set return_sequences=True, our output will have the shape (num_seq, num_feature), \n",
    "    # but if we do, we will obtain the output with shape (num_seq, seq_len, num_feature).\n",
    "    model.add(LSTM(128, input_shape=net_in.shape[1:], return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "def train(model, net_in, net_out, epochs):\n",
    "    filepath = \"weights.best.music3.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose=0, save_best_only = True)\n",
    "    \n",
    "    model.fit(net_in, net_out, epochs = epochs, batch_size = 32, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net():\n",
    "    epochs = 200\n",
    "    notes = get_notes()\n",
    "    n_vocab = len(set(notes))\n",
    "    net_in, net_out = prep_seq(notes, n_vocab)\n",
    "    model = net_arch(net_in, n_vocab)\n",
    "    train(model, net_in, net_out, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
